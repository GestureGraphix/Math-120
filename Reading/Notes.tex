\documentclass{report}

\input{preamble}
\input{macros}
\input{letterfonts}

\title{\Huge{Math 120 QR}}
\author{\huge{Alex Hernandez Juarez}}
\date{Fall 2024}

\begin{document}

\maketitle
\newpage% or \cleardoublepage
% \pdfbookmark[<level>]{<title>}{<dest>}
\pdfbookmark[section]{\contentsname}{toc}
\tableofcontents
\pagebreak

\chapter{}
\section{12.1 Notes (Three Dimensional Coodinate Systems)}

\defrose{Distance Formula}{DDefintion: 
	\begin{center}
		\[ |P_{1}P_{2}| = \sqrt{(x_{2} - x_{1})^{2} + (y_{2} - y_{1})^{2} + (z_{2} - z_{1})^{2} }\] 
	\end{center}
}

\defrose{Equation of a sphere}{
	DDefintion: An equation of a sphere with center $C(h,k,l)$, and radius $r$ is 
	\begin{center}
		\[ (x-h)^{2} + (y-k)^{2} + (z-l)^{2}\] 
	\end{center}
	In particular, if the center is the origin $O$, than an equation of the sphere is 
	\begin{center}
		\[ x^{2} + y^{2} + z^{2}\] 
	\end{center}
}
		
\section{12.2 Notes (Vectors)}

\defrose{Vector Addition}{IIf $\textbf{u}$ and $\textbf{v}$ are vectors positioned so the initial
point of $\textbf{v}$ is at the terminal point of $\textbf{u}$, then the $\textbf{sum u + v}$ is the vector from the
initial point of $\textbf{u}$ to the terminal point of $\textbf{v}$.}

\defrose{Scalar Multiplication}{IIf $c$ is a scalar and $\textbf{v}$ is a vector, then the
$\textbf{scalar multiple}$ $c \textbf{v}$ is the vector whose length is $|c|$ times the length of $\textbf{v}$ and whose direction is
the same as $\textbf{v}$ if $c > 0$ and is opposite to $\textbf{v}$ if $c=0$ or $\textbf{v}$ = 0, then c$\textbf{v} = 0$ }


\exrose{}{Given the points $A(x_{1}, y_{1},z_{1})$ and $B(x_{2}, y_{2}, z_{2})$, the vector $\textbf{a}$ with represenation 
	$\ray{AB}$ is: 
	\begin{center}
		\[ a = \langle x_{2} - x_{1}, y_{2}-y_{1}, z_{2} - z_{1} \rangle \] 
	\end{center}
}


\exrose{}{
	If $\textbf{a}  = \langle a_{1}, a_{2}\rangle$ and $\textbf{b} = \langle b_{1}, b_{2} \rangle$, then: 
	\begin{center}
		\[ \textbf{a} + \textbf{b} = \langle a_{1} + b_{1}, a_{2} + b_{2} \rangle \]
		\[ \textbf{a} - \textbf{b} = \langle a_{1} - b_{1}, a_{2} - b_{2} \rangle \]
		\[ c\textbf{a} = \langle ca_{1}, ca_{2} \rangle \]   
	\end{center} 
	
	Similarily, for three demensional vectors, 

	\begin{center}
		\[ \langle a_{1}, a_{2}, a_{3} \rangle + \langle b_{1}, b_{2}, b_{3} \rangle = \langle a_{1} + b_{1}, a_{2} + a_{3} + b_{3} \rangle \] 
		\[ \langle a_{1}, a_{2}, a_{3} \rangle - \langle b_{1}, b_{2}, b_{3} \rangle = \langle a_{1} - b_{1}, a_{2} - a_{3} - b_{3} \rangle \] 
		\[ c \langle a_{1}, a_{2}, a_{3} \rangle =  \langle ca_{1}, ca_{2}, ca_{3} \rangle \] 
	\end{center} 

}

\ntimg{Properties of vectors: If $\textbf{a}$, $\textbf{b}$, and $\textbf{c}$ are vectors in $V_{n}$ and $c$ and $d$ are scalars than 
	\begin{itemize}
		\item $\textbf{a} + \textbf{b} = \textbf{b} + \textbf{a}$
		\item $a + (\textbf{b} + \textbf{c}) = (\textbf{a} + \textbf{b}) + \textbf{c} $
		\item $\textbf{a} + 0 = \textbf{a}$
		\item $ \textbf{a} + \textbf{a} + \textbf{-a} = 0 $
		\item $c(\textbf{a} + \textbf{b}) = c\textbf{a} + c\textbf{b}$ 
		\item $(c + d)a = c \textbf{a} + d \textbf{a} $
		\item $(cd) \textbf{a} = c(d\textbf{a})$
		\item $l\textbf{a} = \textbf{a} $
	\end{itemize}
}

\section{12.3 Notes (Dot Product)}

\defrose{Dot Product}{
	IIf $\textbf{a} = \langle a_{1}, a_{2}, a_{3} \rangle $ and $\textbf{b} = \langle b_{1}, b_{2}, 
	b_{3} \rangle $, then the $\textbf{dot  product}$ of $\mathbf{a}$ and $\mathbf{b}$ is the number $\textbf{a} \cdot \textbf{b}$ given by 
	\begin{center}
		\[ \textbf{a} \cdot \textbf{b} = a_{1}b_{1} + a_{2}b_{2} + a_{3}b_{3} \] 
	\end{center} 
	Properties of the Dot Product: If $\mathbf{a}, \mathbf{b},$ and $\mathbf{c}$ are vectors in $V_3$ and $c$ is a scalar, then 
	\begin{enumerate}
		\item $\mathbf{a} \cdot \mathbf{a} = |\mathbf{a}|^2$
		\item $\mathbf{a} \cdot \mathbf{b} = \mathbf{b} \cdot \mathbf{a}$
		\item $\mathbf{a} \cdot (\mathbf{b} + \mathbf{c}) = \mathbf{a} \cdot \mathbf{b} + \mathbf{a} \cdot \mathbf{c}$
		\item $(c\mathbf{a}) \cdot \mathbf{b} = c(\mathbf{a} \cdot \mathbf{b}) = \mathbf{a} \cdot (c\mathbf{b})$
		\item $\mathbf{0} \cdot \mathbf{a} = 0$
	\end{enumerate} 
}

\defrose{Geometric Definition of the Dot Product}{IIf $\theta$ is the angle between vectors $\mathbf{a}$ and $\mathbf{b}$, then 
	\begin{center}
		\[ \mathbf{a} \cdot \mathbf{b} = |\mathbf{a}| |\mathbf{b}| \cos(\theta) \] 
	\end{center}
	Proof: 
	\begin{center}
		\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45, scale=1.5]
			% Axes
			\draw[->] (0,0,0) -- (2,0,0) node[anchor=north east]{$x$};
			\draw[->] (0,0,0) -- (0,2,0) node[anchor=north west]{$y$};
			\draw[->] (0,0,0) -- (0,0,2) node[anchor=south]{$z$};
			
			% Vectors a, b, and a-b
			\draw[->, thick, blue] (0,0,0) -- (2,0,0) node[midway, below]{$\mathbf{a}$} node[anchor=west]{$A$};
			\draw[->, thick, blue] (0,0,0) -- (1,1,0) node[midway, left]{$\mathbf{b}$} node[anchor=east]{$B$};
			\draw[->, thick, blue] (1,1,0) -- (2,0,0) node[midway, above]{$\mathbf{a-b}$};
			
			% Angle label theta
			\draw (0.5,0,0) arc[start angle=0,end angle=45,radius=0.5] node[midway, right]{$\theta$};
			
			% Origin O
			\node[anchor=east] at (0,0,0) {$O$};
			
		\end{tikzpicture}
		\[ |AB|^{2} = |OA|^{2} + |OB|^{2} - 2 |OA| |OB| \cos \theta \] 
	\end{center}

	Corollary: If $\theta$ is the angle between nonzero vectors $\mathbf{a}$ and $\mathbf{b}$, then 
	\begin{center}
		\[ \cos(\theta)  = \frac{\mathbf{a} \cdot \mathbf{b} }{|\mathbf{a}| |\mathbf{b}| } \] 
	\end{center}
}

\ntimg{
	Two vectors $\mathbf{a}$ and $\mathbf{b}$ are orthogonal if an only if $\mathbf{a} \cdot \mathbf{b} = 0$
}

\ex{Direction Angles and Cosines}{
	The \textbf{direction angles} of a nonzero vector $\mathbf{a}$ are the angles $\alpha$, $\beta$, and $\gamma$ (in the interval $[0, \pi]$) that $\mathbf{a}$ makes with the positive $x$-, $y$-, and $z$-axes, respectively .

	The cosines of these direction angles, $\cos \alpha$, $\cos \beta$, and $\cos \gamma$, are called the \textbf{direction cosines} of the vector $\mathbf{a}$. Using Corollary 6 with $\mathbf{b}$ replaced by $\mathbf{i}$, we obtain:

	\[ \cos \alpha = \frac{\mathbf{a} \cdot \mathbf{i}}{|\mathbf{a}||\mathbf{i}|} = \frac{a_1}{|\mathbf{a}|} \tag{1} \]

	Similarly, we also have:
	\[ \cos \beta = \frac{a_2}{|\mathbf{a}|} \quad \text{and} \quad \cos \gamma = \frac{a_3}{|\mathbf{a}|} \tag{2} \]
	By squaring the expressions in Equations 8 and 9 and adding, we see that:
	\[ \cos^2 \alpha + \cos^2 \beta + \cos^2 \gamma = 1 \tag{3} \]
	We can also use Equations 8 and 9 to write:
	\[ \mathbf{a} = \langle a_1, a_2, a_3 \rangle = \langle |\mathbf{a}| \cos \alpha, |\mathbf{a}| \cos \beta, |\mathbf{a}| \cos \gamma \rangle
	= |\mathbf{a}| \langle \cos \alpha, \cos \beta, \cos \gamma \rangle \]
	Therefore,
	\[ \frac{1}{|\mathbf{a}|} \mathbf{a} = \langle \cos \alpha, \cos \beta, \cos \gamma \rangle \tag{4} \]
	which says that the direction cosines of $\mathbf{a}$ are the components of the unit vector in the direction of $\mathbf{a}$.

}

\defrose{Projections}{
	TThe \textbf{scalar projection} of $\mathbf{b}$ onto $\mathbf{a}$ (also called the \textbf{component of $\mathbf{b}$ along $\mathbf{a}$}) is defined to be the signed magnitude of the vector projection, which is the number $|\mathbf{b}| \cos \theta$, where $\theta$ is the angle between $\mathbf{a}$ and $\mathbf{b}$.
	This is denoted by $\text{comp}_{\mathbf{a}} \mathbf{b}$. Observe that it is negative if $\pi/2 < \theta \leq \pi$. The equation
	\[ 	\mathbf{a} \cdot \mathbf{b} = |\mathbf{a}| |\mathbf{b}| \cos \theta = |\mathbf{a}| (|\mathbf{b}| \cos \theta) \]
	shows that the dot product of $\mathbf{a}$ and $\mathbf{b}$ can be interpreted as the length of $\mathbf{a}$ times the scalar projection of $\mathbf{b}$ onto $\mathbf{a}$. Since
	\[ 	|\mathbf{b}| \cos \theta = \frac{\mathbf{a} \cdot \mathbf{b}}{|\mathbf{a}|} = \frac{\mathbf{a}}{|\mathbf{a}|} \cdot \mathbf{b} \]
	the component of $\mathbf{b}$ along $\mathbf{a}$ can be computed by taking the dot product of $\mathbf{b}$ with the unit vector in the direction of $\mathbf{a}$. We summarize these ideas as follows.
	\\
	\textbf{Scalar projection of $\mathbf{b}$ onto $\mathbf{a}$:} \quad $\text{comp}_{\mathbf{a}} \mathbf{b} = \frac{\mathbf{a} \cdot \mathbf{b}}{|\mathbf{a}|}$


	\textbf{Vector projection of $\mathbf{b}$ onto $\mathbf{a}$:} \quad $\text{proj}_{\mathbf{a}} \mathbf{b} = \left( \frac{\mathbf{a} \cdot \mathbf{b}}{|\mathbf{a}|^2} \right) \mathbf{a} = \frac{\mathbf{a} \cdot \mathbf{b}}{|\mathbf{a}|^2} \mathbf{a}$
}


\section{12.4 Notes (Cross Product)}

\defrose{Cross Product}{
	GGiven two nonzero vectors $\mathbf{a} = \langle a_1, a_2, a_3 \rangle$ and $\mathbf{b} = \langle b_1, b_2, b_3 \rangle$, suppose that a nonzero vector $\mathbf{c} = \langle c_1, c_2, c_3 \rangle$ is perpendicular to both $\mathbf{a}$ and $\mathbf{b}$. Then $\mathbf{a} \cdot \mathbf{c} = 0$ and $\mathbf{b} \cdot \mathbf{c} = 0$, and so:

	\begin{align}
	a_1c_1 + a_2c_2 + a_3c_3 &= 0 \tag{1} \\
	b_1c_1 + b_2c_2 + b_3c_3 &= 0 \tag{2}
	\end{align}

	To eliminate $c_3$, we multiply (1) by $b_3$ and (2) by $a_3$ and subtract:

	\[ (a_1b_3 - a_3b_1)c_1 + (a_2b_3 - a_3b_2)c_2 = 0 \tag{3} \]

	Equation (3) has the form $pc_1 + qc_2 = 0$, for which an obvious solution is $c_1 = q$ and $c_2 = -p$. So, a solution of (3) is:

	\begin{align*}
		c_1 &= a_2b_3 - a_3b_2 \\
		c_2 &= a_3b_1 - a_1b_3
	\end{align*}

	Substituting these values into (1) and (2), we then get:

	\[ 	c_3 = a_1b_2 - a_2b_1 	\]

	This means that a vector perpendicular to both $\mathbf{a}$ and $\mathbf{b}$ is:

	\[ 	\langle c_1, c_2, c_3 \rangle = \langle a_2b_3 - a_3b_2, a_3b_1 - a_1b_3, a_1b_2 - a_2b_1 \rangle \]

	The resulting vector is called the \textbf{cross product} of $\mathbf{a}$ and $\mathbf{b}$ and is denoted by $\mathbf{a} \times \mathbf{b}$.

}

\defrose{Cross Product of two vectors}{
	IIf $\mathbf{a} = \langle a_{1}, a_{2}, a_{3} \rangle $ and $\mathbf{b} = \langle b_{1}, b_{2}, b_{3} \rangle $ 
	then the \textbf{cross product} of \textbf{a} and \textbf{b} is: 
	\begin{center}
		\[ \mathbf{a} \times \mathbf{b} = \langle a_{2}b_{3} - a_{3}b_{2}, a_{3}b_{1} - a_{1}b_{3}, a_{1}b_{2} - a_{2}b_{1} \rangle \] 
	\end{center}
}

\ntimg{Determinant of order 2: 
	\begin{center}
		\[ \begin{vmatrix}
		a & b \\
		c & d
		\end{vmatrix}
		= ad - bc \]
	\end{center}
}

\ntimg{Determinant of order 3: 
	\[ 
	\begin{vmatrix}
	a_1 & a_2 & a_3 \\
	b_1 & b_2 & b_3 \\
	c_1 & c_2 & c_3
	\end{vmatrix}
	= a_1
	\begin{vmatrix}
	b_2 & b_3 \\
	c_2 & c_3
	\end{vmatrix}
	- a_2
	\begin{vmatrix}
	b_1 & b_3 \\
	c_1 & c_3
	\end{vmatrix}
	+ a_3
	\begin{vmatrix}
	b_1 & b_2 \\
	c_1 & c_2
	\end{vmatrix}
	\]
}

\defrose{Second definition of cross product}{
	AArithmetic Definition: 
	\begin{center}
		\[ a \times b = \left[ \begin{matrix}
			i & j & k  \\
			a_{1} & a_{2} & a_{3} \\
			b_{1} & b_{2} & b_{3} \\
		\end{matrix}\right] = |a||b| \sin(\theta) \] 
		\[ \left[ \begin{matrix}
			a_{2} & a_{3} \\
			b_{2} & b_{3}  \\
		\end{matrix}\right] i - \left[ \begin{matrix}
			a_{1} & a_{3} \\
			b_{1} & b_{3}  \\
		\end{matrix}\right] j + \left[ \begin{matrix}
			a_{1} & a_{2} \\
			b_{1} & b_{2} k  \\
		\end{matrix}\right]\] 
		\[ = (a_{2}b_{3} - a_{3}b_{2}) i - (a_{1}b_{3} - a_{3}b_{1}) j + (a_{1} b_{2} - a_{2}b_{1}) k \]\
	\end{center}

	The vector \textbf{a} $\times$ \textbf{b} is orthogonal to both \textbf{a} and \textbf{b} 
}

\exrose{Proof that \textbf{a} $\times$ \textbf{b} is orthogonal to both \textbf{a}}{
	\begin{align*}
		(\mathbf{a} \times \mathbf{b}) \cdot \mathbf{a} &= 
		\begin{vmatrix}
		a_2 & a_3 \\
		b_2 & b_3
		\end{vmatrix} a_1 - 
		\begin{vmatrix}
		a_1 & a_3 \\
		b_1 & b_3
		\end{vmatrix} a_2 + 
		\begin{vmatrix}
		a_1 & a_2 \\
		b_1 & b_2
		\end{vmatrix} a_3 \\
		&= a_1(a_2b_3 - a_3b_2) - a_2(a_1b_3 - a_3b_1) + a_3(a_1b_2 - a_2b_1) \\
		&= a_1a_2b_3 - a_1a_3b_2 - a_2a_1b_3 + a_2a_3b_1 + a_3a_1b_2 - a_3a_2b_1 \\
		&= 0
	\end{align*}
}

\defrose{sin definition of cross product}{
	IIf $\theta$ is the angle between \textbf{a} and \textbf{b} (so $0 \leq \theta \leq \pi$), then 
	the length of the cross product \textbf{a} $\times$ \textbf{b} is given by: 
	\[ |\mathbf{a} \times \mathbf{b} | = |\mathbf{a}| |\mathbf{b}| \sin(\theta) \]
	Proof: 
	\begin{align*}
		|\mathbf{a} \times \mathbf{b}|^2 &= (a_2b_3 - a_3b_2)^2 + (a_3b_1 - a_1b_3)^2 + (a_1b_2 - a_2b_1)^2 \\
		\\
		&= a_2^2b_3^2 - 2a_2a_3b_2b_3 + a_3^2b_2^2 + a_3^2b_1^2 - 2a_1a_3b_1b_3 + a_1^2b_3^2 + a_1^2b_2^2 - 2a_1a_2b_1b_2 + a_2^2b_1^2 \\
		\\
		&= (a_1^2 + a_2^2 + a_3^2)(b_1^2 + b_2^2 + b_3^2) - (a_1b_1 + a_2b_2 + a_3b_3)^2 \\
		\\
		&= |\mathbf{a}|^2 |\mathbf{b}|^2 - (\mathbf{a} \cdot \mathbf{b})^2 \\
		\\
		&= |\mathbf{a}|^2 |\mathbf{b}|^2 - |\mathbf{a}|^2 |\mathbf{b}|^2 \cos^2 \theta \quad \text{(by Theorem 12.3.3)} \\
		\\
		&= |\mathbf{a}|^2 |\mathbf{b}|^2 (1 - \cos^2 \theta) \\
		\\
		&= |\mathbf{a}|^2 |\mathbf{b}|^2 \sin^2 \theta
	\end{align*}

	Taking square roots and observing that \(\sqrt{\sin^2 \theta} = \sin \theta\) because \(\sin \theta \geq 0\) when \(0 \leq \theta \leq \pi\), we have
	\[ |\mathbf{a} \times \mathbf{b}| = |\mathbf{a}| |\mathbf{b}| \sin \theta \]
}

\ntimg{
	Two nonzero vectors \textbf{a} and \textbf{b} are parallel if and only if 
	\[ \mathbf{a} \times \mathbf{b} = 0 \] 
}

\exrose{Geometric interpretation of $|\mathbf{a} \times \mathbf{b}| = |\mathbf{a}| |\mathbf{b}| \sin \theta$}{
	If \textbf{a} and \textbf{b} are represented by directed line segments with the same inital point, then they determine 
	a parallelogram with base $|\mathbf{a}|$, altitude $\mathbf{b}\sin(\theta)$ and area 
	\[ A = |\mathbf{a}|(|\mathbf{b}| \sin \theta ) = |\mathbf{a} \times \mathbf{b}|  \] 
	Thus we have the following way of interpreting the magnitude of a cross product: \\
	The length of the cross product of \textbf{a} $\times$ \textbf{b} is equal to the area of the 
	parallelogram determined by \textbf{a} and \textbf{b} 
}

\ntimg{
	If we apply the following theorem:

	The vector \(\mathbf{a} \times \mathbf{b}\) is orthogonal to both \(\mathbf{a}\) and \(\mathbf{b}\), and 
	\[ 	|\mathbf{a} \times \mathbf{b}| = |\mathbf{a}| |\mathbf{b}| \sin \theta \]
	to the standard basis vectors \(\mathbf{i}, \mathbf{j}, \mathbf{k}\) using \(\theta = \frac{\pi}{2}\), we obtain

	\[
	\begin{aligned}
		\mathbf{i} \times \mathbf{j} &= \mathbf{k} \quad &\mathbf{j} \times \mathbf{k} &= \mathbf{i} \quad &\mathbf{k} \times \mathbf{i} &= \mathbf{j} \\
		\mathbf{j} \times \mathbf{i} &= -\mathbf{k} \quad &\mathbf{k} \times \mathbf{j} &= -\mathbf{i} \quad &\mathbf{i} \times \mathbf{k} &= -\mathbf{j}
	\end{aligned}
	\]
}


\ntimg{
	If \(\mathbf{a}\), \(\mathbf{b}\), and \(\mathbf{c}\) are vectors and \(c\) is a scalar, then
	\begin{enumerate}
		\item \(\mathbf{a} \times \mathbf{b} = -\mathbf{b} \times \mathbf{a}\)
		\item \((c\mathbf{a}) \times \mathbf{b} = c(\mathbf{a} \times \mathbf{b}) = \mathbf{a} \times (c\mathbf{b})\)
		\item \(\mathbf{a} \times (\mathbf{b} + \mathbf{c}) = \mathbf{a} \times \mathbf{b} + \mathbf{a} \times \mathbf{c}\)
		\item \((\mathbf{a} + \mathbf{b}) \times \mathbf{c} = \mathbf{a} \times \mathbf{c} + \mathbf{b} \times \mathbf{c}\)
		\item \(\mathbf{a} \cdot (\mathbf{b} \times \mathbf{c}) = (\mathbf{a} \times \mathbf{b}) \cdot \mathbf{c}\)
		\item \(\mathbf{a} \times (\mathbf{b} \times \mathbf{c}) = (\mathbf{a} \cdot \mathbf{c})\mathbf{b} - (\mathbf{a} \cdot \mathbf{b})\mathbf{c}\)
	\end{enumerate}
}

\exrose{Proof of property 5 of cross products}{
	If \(\mathbf{a} = \langle a_1, a_2, a_3 \rangle\), \(\mathbf{b} = \langle b_1, b_2, b_3 \rangle\), and \(\mathbf{c} = \langle c_1, c_2, c_3 \rangle\), then: 
	\begin{align*}
		\mathbf{a} \cdot (\mathbf{b} \times \mathbf{c}) &= a_1(b_2c_3 - b_3c_2) + a_2(b_3c_1 - b_1c_3) + a_3(b_1c_2 - b_2c_1)\\ 
		\\
		&= a_1b_2c_3 - a_1b_3c_2 + a_2b_3c_1 - a_2b_1c_3 + a_3b_1c_2 - a_3b_2c_1 \\
		\\
		&= (a_2b_3 - a_3b_2)c_1 + (a_3b_1 - a_1b_3)c_2 + (a_1b_2 - a_2b_1)c_3 \\
		\\
		&= (\mathbf{a} \times \mathbf{b}) \cdot \mathbf{c} \\
	\end{align*}
}

\defrose{Triple Products}{ 
	TThe product \(\mathbf{a} \cdot (\mathbf{b} \times \mathbf{c})\) that occurs in Property 5 is called the \textit{scalar triple product} of the vectors \(\mathbf{a}\), \(\mathbf{b}\), and \(\mathbf{c}\). 

	\[ 	\mathbf{a} \cdot (\mathbf{b} \times \mathbf{c}) = 
	\begin{vmatrix}
	a_1 & a_2 & a_3 \\
	b_1 & b_2 & b_3 \\
	c_1 & c_2 & c_3
	\end{vmatrix} \]
	
	The geometric significance of the scalar triple product can be seen by considering the parallelepiped determined by the vectors \(\mathbf{a}\), \(\mathbf{b}\), and \(\mathbf{c}\). The area of the base parallelogram is \(A = |\mathbf{b} \times \mathbf{c}|\). If \(\theta\) is the angle between \(\mathbf{a}\) and \(\mathbf{b} \times \mathbf{c}\), then the height \(h\) of the parallelepiped is \(h = |\mathbf{a}| |\cos \theta|\). (We must use \(|\cos \theta|\) instead of \(\cos \theta\) in case \(\theta > \pi / 2\).) Therefore, the volume of the parallelepiped is
	
	\[ 	V = A h = |\mathbf{b} \times \mathbf{c}| |\mathbf{a}| |\cos \theta| = |\mathbf{a} \cdot (\mathbf{b} \times \mathbf{c})| \]
	
	Thus, we have proved the following formula: 
	The volume of the parallelepiped determined by the vectors \textbf{a}, \textbf{b}, and \textbf{c} is the magnitude of their scalar triple product:
	\[ V = |\mathbf{a} \cdot (\mathbf{b} \times \mathbf{c})| \] 
 }
 
 \ntimg{
	If we use the formula in $V = |\mathbf{a} \cdot (\mathbf{b} \times \mathbf{c})|$ and discover that the volume of the parallelepiped
	determined by a, b, and c is 0, then the vectors must lie in the same plane; that is, they
	are coplanar
 }
 \section{12.5 Notes (Equations of Lines and Planes)}

\defrose{Hi}{
	LLikewise, a line \(L\) in three-dimensional space is determined when we know a point
	\(P_0(x_0, y_0, z_0)\) on \(L\) and a direction for \(L\), which is conveniently 
	described by a vector \(\mathbf{v}\) parallel to the line. Let \(P(x, y, z)\) be an
	arbitrary point on \(L\) and let \(\mathbf{r_0}\) and \(\mathbf{r}\) be the position
	vectors of \(P_0\) and \(P\) (that is, they have representations
	\(\overrightarrow{OP_0}\) and \(\overrightarrow{OP}\)). If \(\mathbf{a}\) is the
	vector with representation \(\overrightarrow{P_0P}\), as in Figure 1, then the
	Triangle Law for vector addition gives

	\[
	\mathbf{r} = \mathbf{r_0} + \mathbf{a}.
	\]

	\insertpng[0.25]{lines.png}
	Since \textbf{a} and \textbf{v} are parallel vectors, there is a scalar \textit{t} such that 
	$\mathbf{a} = t \mathbf{v} $ Thus  
	\[ r = r_{0} + t \mathbf{v}\] 
}

\ntimg{
	If the vector \(\mathbf{v}\) that gives the direction of the line \(L\) is written in component form as 
	\[ 	\mathbf{v} = \langle a, b, c \rangle, \]
	then we have \( t\mathbf{v} = \langle ta, tb, tc \rangle \). We can also write \(\mathbf{r} = \langle x, y, z \rangle\) and 
	\[ 	\mathbf{r}_0 = \langle x_0, y_0, z_0 \rangle, \]
	so the vector equation (1) becomes 
	\[	\langle x, y, z \rangle = \langle x_0 + ta, y_0 + tb, z_0 + tc \rangle. \]
	Two vectors are equal if and only if corresponding components are equal. Therefore we have the three scalar equations:
	\[ 	x = x_0 + at \quad y = y_0 + bt \quad z = z_0 + ct 	\]
}

\exrose{Line example}{
	Find a vector equation and parametric equations for the line that passes through the point \((5, 1, 3)\) and is parallel to the vector \(\mathbf{i} + 4\mathbf{j} - 2\mathbf{k}\).
	Here \(\mathbf{r}_0 = \langle 5, 1, 3 \rangle = 5\mathbf{i} + \mathbf{j} + 3\mathbf{k}\) and \(\mathbf{v} = \mathbf{i} + 4\mathbf{j} - 2\mathbf{k}\), so the vector equation (1) becomes
	\[ \mathbf{r} = (5\mathbf{i} + \mathbf{j} + 3\mathbf{k}) + t(\mathbf{i} + 4\mathbf{j} - 2\mathbf{k}) \]
	or
	\[ \mathbf{r} = (5 + t)\mathbf{i} + (1 + 4t)\mathbf{j} + (3 - 2t)\mathbf{k} \]
	Parametric equations are
	\[ x = 5 + t \quad y = 1 + 4t \quad z = 3 - 2t \]
}

\ntimg{
	In general, if a vector \(\mathbf{v} = \langle a, b, c \rangle\) is used to describe
	the direction of a line \(L\), then the numbers \(a\), \(b\), and \(c\) are called 
	\textit{direction numbers} of \(L\). Since any vector parallel to \(\mathbf{v}\) could
	 also be used, we see that any three numbers proportional to \(a\), \(b\), and \(c\) 
	could also be used as a set of direction numbers for \(L\). \\

	Another way of describing a line \(L\) is to eliminate the parameter \(t\) 
	from Equations 2. If none of \(a\), \(b\), or \(c\) is 0, we can solve each of
	 these equations for \(t\):

	\[ 	t = \frac{x - x_0}{a} \quad t = \frac{y - y_0}{b} \quad t = \frac{z - z_0}{c} \]

	Equating the results, we obtain
	\[ \frac{x - x_0}{a} = \frac{y - y_0}{b} = \frac{z - z_0}{c} \]

	These equations are called symetric equations of \(L\) 
}

\defrose{Line segment}{
	TThe line segment from $r_{0}$ to $r_{1}$ is given by the vector equation 
	\[ \mathbf{r}(t) = (1-t)\mathbf{r_{0}} + tr_{1} \quad 0 \leq t \leq 1\] 
}

\defrose{Planes}{
	AA plane in space is determined by a point $P_0(x_0, y_0, z_0)$ in the plane and a
	vector $\mathbf{n}$ that is orthogonal to the plane. This orthogonal vector
	$\mathbf{n}$ is called a \textbf{normal vector}. Let $P(x, y, z)$ be an arbitrary
	 point in the plane, and let $\mathbf{r_0}$ and $\mathbf{r}$ be the position vectors
	of $P_0$ and $P$. Then the vector $\mathbf{r - r_0}$ is represented by
	$\overrightarrow{P_0P}$.

	The normal vector $\mathbf{n}$ is orthogonal to every vector in the given plane. 
	In particular, $\mathbf{n}$ is orthogonal to $\mathbf{r - r_0}$ and so we have
	\begin{equation}
		\mathbf{n} \cdot (\mathbf{r} - \mathbf{r_0}) = 0
	\end{equation}
	which can be rewritten as
	\begin{equation}
		\mathbf{n} \cdot \mathbf{r} = \mathbf{n} \cdot \mathbf{r_0}
	\end{equation}
	These can be reffered to as the \textbf{vector equation of the plane}

	To obtain a scalar equation for the plane, we write \textbf{n} $ = \langle a, b, c \rangle, 
	\mathbf{r} = \langle x, y, x \rangle$, and $\mathbf{r}_{0} = \langle x_{0}, y_{0}, z_{0} \rangle$. then the 
	vector equation becomes: 
	\[ \langle a, b, c \rangle \cdot \langle x - x_{0}, y - y_{0}, z - z_{0} \rangle = 0 \] 

	Expanding the left side of this equation gives the following: \\
	A \textbf{scalar equation of the plane} through the point $P_{0}(x_{0}, y_{0}, z_{0})$ with normal vector 
	\textbf{n} $ = \langle a, b, c \rangle$ is 
	\[ a(x - x_{0}) + b(y - y_{0}) + c(z - z_{0}) = 0 \]
	by colecting terms can be rewritten as: 
	\[ ax + by + cz + d = 0 \]    
}

\defrose{Distance of a plane}{
	IIn order to find a formula for the distance $D$ from a point $P_1(x_1, y_1, z_1)$ to the plane $ax + by + cz + d = 0$, we let $P_0(x_0, y_0, z_0)$ be any point in the given plane and $\mathbf{b}$ be the vector corresponding to $\overrightarrow{P_0 P_1}$. Then

	\[ 	\mathbf{b} = \langle x_1 - x_0, y_1 - y_0, z_1 - z_0 \rangle \]
	
	\begin{center}
		\insertpng[0.6]{distances.png}
	\end{center}

	From Figure, you can see that the distance $D$ from $P_1$ to the plane is equal to the absolute value of the scalar projection of $\mathbf{b}$ onto the normal vector $\mathbf{n} = \langle a, b, c \rangle$. Thus,

	\[ 	D = |\text{comp}_{\mathbf{n}} \mathbf{b}| = \frac{|\mathbf{n} \cdot \mathbf{b}|}{|\mathbf{n}|} \]

	\[ 	= \frac{|a(x_1 - x_0) + b(y_1 - y_0) + c(z_1 - z_0)|}{\sqrt{a^2 + b^2 + c^2}} \]

	\[	= \frac{|(a x_1 + b y_1 + c z_1) - (a x_0 + b y_0 + c z_0)|}{\sqrt{a^2 + b^2 + c^2}} \]
}

\section{12.6 Reading Notes (Cylinders and Quadric Surfaces)}

\defrose{Cylinder}{
	AA cylinder is a surface that consists of all lines (called rulings) that are parallel to a
	given line and pass through a given plane curve.
}

\defrose{Quadric Surfaces}{
	AA  Quadric Surface is the graph of a second-degree equation in three variables $x$, $y$, and $z$. The most general such equation is
	\[ Ax^2 + By^2 + Cz^2 + Dxy + Eyz + Fzx + Gx + Hy + Iz + J = 0 \]

	where $A$, $B$, $C$, $\dots$, $J$ are constants, but by translation and rotation it can be brought into one of the two \textit{standard forms}

	\[ Ax^2 + By^2 + Cz^2 + J = 0 \quad \text{or} \quad Ax^2 + By^2 + Iz = 0 \] 
}

\exrose{Graphs of Quadric Surfaces PT 1}{
	Ellipsoid: 
	\insertpng[0.7]{ellipsoid.png}
	\[ \frac{x^2}{a^2} + \frac{y^2}{b^2} + \frac{z^2}{c^2} = 1 \] 
	All traces are ellipses. If \(a = b = c\), the ellipsoid is a sphere. \\
	\insertpng[0.7]{EllipticParaboloid.png}
	\[ \frac{z}{c} = \frac{x^2}{a^2} + \frac{y^2}{b^2} \] 
	Horizontal traces are ellipses. Vertical traces are parabolas. The variable raised to the first power indicates the axis of the paraboloid. \\
	\insertpng[0.7]{HyperbolicParaboloid}
	\[ \frac{z}{c} = \frac{x^2}{a^2} - \frac{y^2}{b^2} \] 
	Horizontal traces are hyperbolas. Vertical traces are parabolas. The case where \(c < 0\) is illustrated. \\
}

\exrose{Quadric Surfaces Pt 2}{
	\insertpng[0.7]{Cone.png}
	\[ \frac{z^2}{c^2} = \frac{x^2}{a^2} + \frac{y^2}{b^2} \] 
	Horizontal traces are ellipses. Vertical traces in the planes \(x = k\) and \(y = k\) are hyperbolas if \(k \neq 0\) but are pairs of lines if \(k = 0\). \\
	\insertpng[0.7]{HyperboloidofOneSheet.png}
	\[ \frac{x^2}{a^2} + \frac{y^2}{b^2} - \frac{z^2}{c^2} = 1 \] 
	Horizontal traces are ellipses. Vertical traces are hyperbolas. The axis of symmetry corresponds to the variable whose coefficient is negative. \\
	\insertpng[0.7]{HyperboloidofTwoSheets.png}
	\[ -\frac{x^2}{a^2} - \frac{y^2}{b^2} + \frac{z^2}{c^2} = 1 \] 
	Horizontal traces in \(z = k\) are ellipses if \(k > c\) or \(k < -c\). Vertical traces are hyperbolas. The two minus signs indicate two sheets. \\
}

\chapter{}
\section{13.1 Reading Notes(Vector Functions and Space Curves)}

\defrose{Vector Value Functions}{
	AA \textbf{vector-valued function}, or \textbf{vector function}, is simply a function whose
	domain is a set of real numbers and whose range is a set of vectors. We are most 
	interested in vector functions r whose values are three-dimensional vectors. If
	$f(t)$, $g(t)$, and $h(t)$ are the components of the vector \textbf{r}$(t)$, then $f$ , $g$, and $h$ are real-valued
	functions called the \textbf{component functions} of r and we can write

	\[ \mathbf{r}(t) = \langle f(t), g(t), h(t) \rangle = f(t) \mathbf{i} + g(t) \mathbf{j} + h(t) \mathbf{k} \]
	We use the letter \( t \) to denote the independent variable because it represents time in most applications of vector functions.
}

\defrose{Limit of Vectors}{
	TThe \textbf{limit} of a vector function \(\mathbf{r}\) is defined by taking the limits of its component functions as follows.

    If $(\mathbf{r}(t) = \langle f(t), g(t), h(t) \rangle)$, then
    \[ \lim_{t \to a} \mathbf{r}(t) = \left\langle \lim_{t \to a} f(t), \lim_{t \to a} g(t), \lim_{t \to a} h(t) \right\rangle \]
    provided the limits of the component functions exist.
}

\defrose{Space Curves}{
	There is a close connection between continuous vector functions and space curves. Suppose that \( f \), \( g \), and \( h \) are continuous real-valued functions on an interval \( I \). Then the set \( C \) of all points \( (x, y, z) \) in space, where
	\[ x = f(t) \quad y = g(t) \quad z = h(t) \]
	and $( t )$ varies throughout the interval \( I \), is called a \textbf{space curve}.
    The equations in are called \textbf{parametric equations of} \( C \) and \( t \) is called a \textbf{parameter}.
}

\section{13.2 Notes (Derivatives and Integrals of Vector Functions)}

\defrose{Derivatives}{
	TThe derivative \(\mathbf{r}'\) of a vector function \(\mathbf{r}\) is defined in much the same way as for real-valued functions:
	\[ \frac{d\mathbf{r}}{dt} = \mathbf{r}'(t) = \lim_{h \to 0} \frac{\mathbf{r}(t+h) - \mathbf{r}(t)}{h} \]
}

\defrose{Derivatives of vectors pt 2}{
	The following theorem gives us a convenient method for computing the derivative of a vector function \(\mathbf{r}\): just differentiate each component of \(\mathbf{r}\).
	\textbf{Theorem} If \(\mathbf{r}(t) = \langle f(t), g(t), h(t) \rangle = f(t) \mathbf{i} + g(t) \mathbf{j} + h(t) \mathbf{k}\), where \(f\), \(g\), and \(h\) are differentiable functions, then
	\[ \mathbf{r}'(t) = \langle f'(t), g'(t), h'(t) \rangle = f'(t) \mathbf{i} + g'(t) \mathbf{j} + h'(t) \mathbf{k} \]
}

\exrose{Proof of Definition 2.2.2}{
	\[ \mathbf{r}'(t) = \lim_{\Delta t \to 0} \frac{1}{\Delta t} [\mathbf{r}(t + \Delta t) - \mathbf{r}(t)] \]
	\[ 	= \lim_{\Delta t \to 0} \frac{1}{\Delta t} [\langle f(t + \Delta t), g(t + \Delta t), h(t + \Delta t) \rangle - \langle f(t), g(t), h(t) \rangle] \]
	\[ 	= \lim_{\Delta t \to 0} \left\langle \frac{f(t + \Delta t) - f(t)}{\Delta t}, \frac{g(t + \Delta t) - g(t)}{\Delta t}, \frac{h(t + \Delta t) - h(t)}{\Delta t} \right\rangle \]
	\[ 	= \left\langle \lim_{\Delta t \to 0} \frac{f(t + \Delta t) - f(t)}{\Delta t}, \lim_{\Delta t \to 0} \frac{g(t + \Delta t) - g(t)}{\Delta t}, \lim_{\Delta t \to 0} \frac{h(t + \Delta t) - h(t)}{\Delta t} \right\rangle \]
	\[ 	= \langle f'(t), g'(t), h'(t) \rangle \]
	A unit vector that has the same direction as the tangent vector is called the \textbf{unit tangent vector} \(\mathbf{T}\) and is defined by
	\[ 	\mathbf{T}(t) = \frac{\mathbf{r}'(t)}{|\mathbf{r}'(t)|} \]
}

\defrose{Differentiation Rules}{
	PProof:
	\textbf{Theorem} Suppose \(\mathbf{u}\) and \(\mathbf{v}\) are differentiable vector functions, \(c\) is a scalar, and \(f\) is a real-valued function. Then
	\begin{enumerate}
		\item \(\frac{d}{dt} [\mathbf{u}(t) + \mathbf{v}(t)] = \mathbf{u}'(t) + \mathbf{v}'(t)\)
		\item \(\frac{d}{dt} [c\mathbf{u}(t)] = c\mathbf{u}'(t)\)
		\item \(\frac{d}{dt} [f(t)\mathbf{u}(t)] = f'(t)\mathbf{u}(t) + f(t)\mathbf{u}'(t)\)
		\item \(\frac{d}{dt} [\mathbf{u}(t) \cdot \mathbf{v}(t)] = \mathbf{u}'(t) \cdot \mathbf{v}(t) + \mathbf{u}(t) \cdot \mathbf{v}'(t)\)
		\item \(\frac{d}{dt} [\mathbf{u}(t) \times \mathbf{v}(t)] = \mathbf{u}'(t) \times \mathbf{v}(t) + \mathbf{u}(t) \times \mathbf{v}'(t)\)
		\item \(\frac{d}{dt} [\mathbf{u}(f(t))] = f'(t) \mathbf{u}'(f(t))\) \hfill \textcolor{blue}{(Chain Rule)}
	\end{enumerate}
}

\ntimg{
	We use Formula 4 to prove the following theorem.
	\textbf{Theorem} If \(|\mathbf{r}(t)| = c\) (a constant), then \(\mathbf{r}'(t)\) is orthogonal to \(\mathbf{r}(t)\) for all \(t\).
}

\defrose{Interation of Vectors}{
	TThe \textbf{definite integral} of a continuous vector function \(\mathbf{r}(t)\) can be defined in much the same way as for real-valued functions except that the integral is a vector. But then we can express the integral of \(\mathbf{r}\) in terms of the integrals of its component functions \(f\), \(g\), and \(h\) as follows. (We use the notation of Chapter 5.)

	\[ \int_a^b \mathbf{r}(t) \, dt = \lim_{n \to \infty} \sum_{j=1}^{n} \mathbf{r}(t_j^*) \, \Delta t \]
	\[ = \lim_{n \to \infty} \left[ \left( \sum_{i=1}^{n} f(t_i^*) \, \Delta t \right) \mathbf{i} + \left( \sum_{i=1}^{n} g(t_i^*) \, \Delta t \right) \mathbf{j} + \left( \sum_{i=1}^{n} h(t_i^*) \, \Delta t \right) \mathbf{k} \right] \]
	and so
	\[ \int_a^b \mathbf{r}(t) \, dt = \left( \int_a^b f(t) \, dt \right) \mathbf{i} + \left( \int_a^b g(t) \, dt \right) \mathbf{j} + \left( \int_a^b h(t) \, dt \right) \mathbf{k} \]
	This means that we can evaluate an integral of a vector function by integrating each component function.

	We can extend the Fundamental Theorem of Calculus to continuous vector functions as follows:
	\[ 	\int_a^b \mathbf{r}(t) \, dt = \mathbf{R}(t) \Big|_a^b = \mathbf{R}(b) - \mathbf{R}(a) \]
	where \(\mathbf{R}\) is an antiderivative of \(\mathbf{r}\), that is, \(\mathbf{R}'(t) = \mathbf{r}(t)\). We use the notation \(\int \mathbf{r}(t) \, dt\) for indefinite integrals (antiderivatives).
}

\section{13.3 Notes (Arc Length and Curvature)}

\defrose{Length of a space curve}{
	SSuppose that the curve has the vector equation $\mathbf{r}(t) = \langle f(t), g(t), h(t) \rangle$, $a \leq t \leq b$, or, equivalently, the parametric equations $x = f(t)$, $y = g(t)$, $z = h(t)$, where $f'$, $g'$, and $h'$ are continuous. If the curve is traversed exactly once as $t$ increases from $a$ to $b$, then it can be shown that its length is
	\begin{equation}
		L = \int_a^b \sqrt{[f'(t)]^2 + [g'(t)]^2 + [h'(t)]^2} \, dt
	\end{equation}
	\begin{equation}
		= \int_a^b \sqrt{\left(\frac{dx}{dt}\right)^2 + \left(\frac{dy}{dt}\right)^2 + \left(\frac{dz}{dt}\right)^2} \, dt
	\end{equation}
	Notice that both of the arc length formulas (1) and (2) can be put into the more compact form
	\begin{equation}
		L = \int_a^b |\mathbf{r}'(t)| \, dt
	\end{equation}
	because, for plane curves $\mathbf{r}(t) = f(t)\mathbf{i} + g(t)\mathbf{j}$,
	\[ |\mathbf{r}'(t)| = |f'(t)\mathbf{i} + g'(t)\mathbf{j}| = \sqrt{[f'(t)]^2 + [g'(t)]^2} \]
	and for space curves $\mathbf{r}(t) = f(t)\mathbf{i} + g(t)\mathbf{j} + h(t)\mathbf{k}$,
	\[	|\mathbf{r}'(t)| = |f'(t)\mathbf{i} + g'(t)\mathbf{j} + h'(t)\mathbf{k}| = \sqrt{[f'(t)]^2 + [g'(t)]^2 + [h'(t)]^2} \]
	A single curve \textit{C} can be respresented by more than one vector function. For instance the 
	twisted cube
	\begin{equation}
		r_{1}(t) = \langle t, t^{2}, t^{3} \rangle \quad 1 \leq t \leq 2  
	\end{equation} 
	could also be represented by the function 
	\begin{equation}
		r_{2} (u) = \langle e^{u}, e^{2u}, e^{3u} \rangle \quad o \leq u \leq \ln 2 
	\end{equation}
	where the connection between the parameters $t$ and $u$ is given by $t = e^{u}$ We say that equations 2.4 and 2.5 are 
	parameterizations of the curve $C$. If we were to use Equation 2.3 to
	compute the length of C using Equations 2.4 and 2.5, we would get the same answer. This is
	because arc length is a geometric property of the curve and hence is independent of the
	parametrization that is used. 
}

\defrose{Arc Length Function}{
	NNow we supose that the curve $C$ is a cruve given by a vector function 
	\[ \mathbf{r} (t) = f(t)\mathbf{i} + g(t) \mathbf{j} + h(t) \mathbf{k} \quad a \leq t \leq b \]
	where \textbf{r}' is continuous and $C$ is transvered exactly once as $t$ increases from $a$ to $b$.
	We define its \textbf{arc length functions} by 
	\begin{equation}
		s(t) = \int_{a}^{t} |\mathbf{r}'(u)| du = \int_{a}^{t} \sqrt{\left(\frac{dx}{du}\right)^{2} + \left(\frac{dy}{du}\right)^{2} + \left(\frac{dz}{du}\right)^{2}} du  
	\end{equation} 
	Thus $s(t)$ is the length of part $C$ between \textbf{r}$(a)$ and \textbf{r}$(t)$. If we differentiate
	both sides of equation 2.6 using part 1 of the Fundamental Theorem of Calculus, we obtain 
	\begin{equation}
		\frac{ds}{dt} = |\mathbf{r}(t)| 
	\end{equation} 
	It is often useful to \textbf{paramterize a curve with respect to arc length} because arc length 
	arises naturally from the shape of the curve and does not depend on a particular coordinate system 
	of a particular parametrization. 
}

\defrose{Curvature}{
	AA parametrization \textbf{r}$(t)$ is called \textbf{smooth} on an interval $I$ if \textbf{r}' is continuous 
	and \textbf{r}'$(t) \neq 0$ on $I$. A curve is called smooth if it has a smooth parameterization. A smooth corner has 
	no cusp or sharp corner; when the tangent vector turns it does so continuously. \\
	\\
	If $C$ is a smooth curve defined by the vector \textbf{r}, recall that the unit tangent vector 
	\textbf{T}(t) is given by 
	\[ \mathbf{T}(t) = \frac{\mathbf{r}'(t)}{|\mathbf{r}'(t)|}\] 
	The curvature of a curve is 
	\begin{equation}
		k = |\frac{d\mathbf{T}}{ds}|
	\end{equation} 
	where \textbf{T} is the unit tangent vector  \\
	\\
	The curvature is easier to compute if it is easier to compute if it is expressed in terms of the paramteter $t$ 
	instead of $s$, so we use the chain rule 
	\[ \frac{d\mathbf{T}}{dt} = \frac{d \mathbf{T}}{ds} \frac{ds}{dt} \Rightarrow k = \left|\frac{d \mathbf{T}}{s}\right| = \left| \frac{d\mathbf{T}/dt}{ds/dt}\right|\] 
	but $ds/dt = |\mathbf{r}'(t|)$ from equation 2.7 
	\begin{equation}
		k(t) = \frac{|\mathbf{T}'(t)|}{|\mathbf{r}'(t)|}
	\end{equation}
	The curvature of the curve given by the vector function \textbf{r} is 
	\begin{equation}
		k(t) = \frac{|\mathbf{r}'(t) \times \mathbf{r}^{n}(t)|}{|\mathbf{r}'(t)|^{3}}
	\end{equation}
}

\ntimg{
	For the special case of a plane curve with equation \(y = f(x)\), we choose \(x\) as the parameter and write \(\mathbf{r}(x) = x\mathbf{i} + f(x)\mathbf{j}\). Then \(\mathbf{r}'(x) = \mathbf{i} + f'(x)\mathbf{j}\) and \(\mathbf{r}''(x) = f''(x)\mathbf{j}\). Since \(\mathbf{i} \times \mathbf{j} = \mathbf{k}\) and \(\mathbf{j} \times \mathbf{j} = 0\), it follows that \(\mathbf{r}'(x) \times \mathbf{r}''(x) = f'(x)\mathbf{k}\). We also have \(|\mathbf{r}'(x)| = \sqrt{1 + [f'(x)]^2}\) and so, by Theorem 10, 

	\begin{equation}
	\kappa(x) = \frac{|f''(x)|}{[1 + (f'(x))^2]^{3/2}} 
	\end{equation}
}

\ntimg{
	At a given point on a smooth space curve \(\mathbf{r}(t)\), there are many vectors that are orthogonal to the unit tangent vector \(\mathbf{T}(t)\). We single out one by observing that, because \(|\mathbf{T}(t)| = 1\) for all \(t\), we have \(\mathbf{T}(t) \cdot \mathbf{T}'(t) = 0\) by Theorem 13.2.4, so \(\mathbf{T}'(t)\) is orthogonal to \(\mathbf{T}(t)\). Note that, typically, \(\mathbf{T}'(t)\) is itself not a unit vector. But at any point where \(\kappa \neq 0\) we can define the \textit{principal unit normal vector} \(\mathbf{N}(t)\) (or simply \textit{unit normal}) as

	\[
	\mathbf{N}(t) = \frac{\mathbf{T}'(t)}{|\mathbf{T}'(t)|}
	\]

	We can think of the unit normal vector as indicating the direction in which the curve is turning at each point. The vector 

	\[
	\mathbf{B}(t) = \mathbf{T}(t) \times \mathbf{N}(t)
	\]
}

\ntimg{
	We summarize here the formulas for unit tangent, unit normal and binormal vectors, and curvature.

	\[
	\mathbf{T}(t) = \frac{\mathbf{r}'(t)}{|\mathbf{r}'(t)|} \quad \mathbf{N}(t) = \frac{\mathbf{T}'(t)}{|\mathbf{T}'(t)|} \quad \mathbf{B}(t) = \mathbf{T}(t) \times \mathbf{N}(t)
	\]
	\[
	\kappa = \left|\frac{d \mathbf{T}}{ds}\right| = \frac{|\mathbf{T}'(t)|}{|\mathbf{r}'(t)|} = \frac{|\mathbf{r}'(t) \times \mathbf{r}''(t)|}{|\mathbf{r}'(t)|^3}
	\]

}

\defrose{Torision }{
	TThe \textbf{torsion} of a curve is 
	\[ \tau = - \frac{d\mathbf{B}}{ds} \cdot \mathbf{N} \]
	Torsion is easier to compute if it is expressed in terms of the parameter \(t\) instead of \(s\), so we use the Chain Rule to write

	\[
	\frac{d\mathbf{B}}{dt} = \frac{d\mathbf{B}}{ds} \frac{ds}{dt} \quad \text{so} \quad \frac{d\mathbf{B}}{ds} = \frac{d\mathbf{B}/dt}{ds/dt} = \frac{\mathbf{B}'(t)}{|\mathbf{r}'(t)|}
	\]

	
	\[
	\tau(t) = \frac{-\mathbf{B}'(t) \cdot \mathbf{N}(t)}{|\mathbf{r}'(t)|}
	\]

	 \textbf{{Theorem}} The torsion of the curve given by the vector function \(\mathbf{r}\) is
	
	\[	\tau(t) = \frac{[\mathbf{r}'(t) \times \mathbf{r}''(t)] \cdot \mathbf{r}'''(t)}{|\mathbf{r}'(t) \times \mathbf{r}''(t)|^2} \]
}

\section{13.4 Notes (Motion in Space: Velocity and Acceleration)}

\chapter{}
\section{14.1 Functions of Several Variables}
\defrose{Functions of Two Variables}{
	DDefintion: A function $f$ of two variables is a rule that assigns to each ordered pair of real numbers $(x, y)$ in a set $D$ a unique real number denoted by $f(x, y)$. The set $D$ is the \textit{domain} of $f$ and its \textit{range} is the set of values that $f$ takes on, that is, $\{ f(x, y) \mid (x, y) \in D \}$.

}

\defrose{Graph of a Function of Two Variables}{
	DDefintion If $f$ is a function of two variables with domain $D$, then the \textit{graph} of $f$ is the set of all points $(x, y, z)$ in $\mathbb{R}^3$ such that $z = f(x, y)$ and $(x, y)$ is in $D$.
}

\defrose{Level Curves and Contour Maps}{
	DDefintion: The \textit{level curves} of a function $f$ of two variables are the curves with equations $f(x, y) = k$, where $k$ is a constant (in the range of $f$).
}

\defrose{Functions of Three Variables}{
	DDefintion: \textbf{A function of three variables}, $f$, is a rule that assigns to each ordered triple $(x, y, z)$ in a domain $D \subseteq \mathbb{R}^3$ a unique real number denoted by $f(x, y, z)$. For instance, the temperature...
}

\section{14.2 Limits and Continuity}

\defrose{Limit of Two Variable Functions}{
	DDefintion: Let $f$ be a function of two variables whose domain $D$ includes points arbitrarily close to $(a, b)$. Then we say that the \textit{limit of} $f(x, y)$ \textit{as} $(x, y)$ \textit{approaches} $(a, b)$ is $L$ and we write
	\[
	\lim_{(x, y) \to (a, b)} f(x, y) = L
	\]
	if for every number $\varepsilon > 0$ there is a corresponding number $\delta > 0$ such that 
	if $(x, y) \in D$ and $0 < \sqrt{(x - a)^2 + (y - b)^2} < \delta$, then $\lvert f(x, y) - L \rvert < \varepsilon$.
	
}

\section{14.3 Partial Derivatives}

\defrose{Partial Derivatives}{
	DDefintion Partial Derivative with respect to x  
	\[ f_x(a, b) = g'(a) \quad \text{where} \quad g(x) = f(x, b) \]
	Defintion Partial Derivative with respect to y  
	\[ f_y(a, b) = h'(a) \quad \text{where} \quad h(x) = f(a, y) \]

}

\ntimg{
	If $z = f(x, y)$, we write

	\[
	f_x(x, y) = f_x = \frac{\partial f}{\partial x} = \frac{\partial}{\partial x} f(x, y) = \frac{\partial z}{\partial x} = f_1 = D_1 f = D_x f
	\]
	
	\[
	f_y(x, y) = f_y = \frac{\partial f}{\partial y} = \frac{\partial}{\partial y} f(x, y) = \frac{\partial z}{\partial y} = f_2 = D_2 f = D_y f
	\]
}

\ntimg{
	{\textbf{Rule for Finding Partial Derivatives of $z = f(x, y)$}}

	\begin{enumerate}
		\item To find $f_x$, regard $y$ as a constant and differentiate $f(x, y)$ with respect to $x$.
		\item To find $f_y$, regard $x$ as a constant and differentiate $f(x, y)$ with respect to $y$.
	\end{enumerate}
}

\defrose{interpretation of Partial Derivatives}{
	TTo understand partial derivatives geometrically, think of the equation 
	$z = f(x, y)$ as representing a surface $S$ (the graph of $f$). If $f(a, b) = c$, 
	then the point $P(a, b, c)$ lies on this surface. \\

	By fixing $y = b$, we focus on the curve $C_1$ where the vertical plane $y = b$ 
	intersects $S$. Similarly, fixing $x = a$ gives us the curve $C_2$, which is 
	where the vertical plane $x = a$ intersects $S$. Both curves $C_1$ and $C_2$ 
	pass through the point $P$. \\

	The curve $C_1$ is the graph of the function $g(x) = f(x, b)$, and the slope of 
	its tangent at $P$ is $f_x(a, b)$. The curve $C_2$ is the graph of $G(y) = f(a, y)$, 
	and the slope of its tangent at $P$ is $f_y(a, b)$. \\

	Thus, the partial derivatives $f_x(a, b)$ and $f_y(a, b)$ represent the slopes 
	of the tangent lines at $P$ along these curves.

	\insertpng[0.25]{partial.png}
}

\defrose{Higher Derivatives}{
	IIf $f$ is a function of two variables, then its partial derivatives $f_x$ and $f_y$ are also functions of two variables, so we can consider their partial derivatives $(f_x)_x$, $(f_x)_y$, $(f_y)_x$, and $(f_y)_y$, which are called the \textit{second partial derivatives} of $f$. If $z = f(x, y)$, we use the following notation:

	\[
	(f_x)_x = f_{xx} = f_{11} = \frac{\partial}{\partial x} \left( \frac{\partial f}{\partial x} \right) = \frac{\partial^2 f}{\partial x^2} = \frac{\partial^2 z}{\partial x^2}
	\]

	\[
	(f_x)_y = f_{xy} = f_{12} = \frac{\partial}{\partial y} \left( \frac{\partial f}{\partial x} \right) = \frac{\partial^2 f}{\partial y \partial x} = \frac{\partial^2 z}{\partial y \partial x}
	\]

	\[
	(f_y)_x = f_{yx} = f_{21} = \frac{\partial}{\partial x} \left( \frac{\partial f}{\partial y} \right) = \frac{\partial^2 f}{\partial x \partial y} = \frac{\partial^2 z}{\partial x \partial y}
	\]

	\[
	(f_y)_y = f_{yy} = f_{22} = \frac{\partial}{\partial y} \left( \frac{\partial f}{\partial y} \right) = \frac{\partial^2 f}{\partial y^2} = \frac{\partial^2 z}{\partial y^2}
	\]

	Thus the notation $f_{xy}$ (or $\frac{\partial^2 f}{\partial y \partial x}$) means that we first differentiate with respect to $x$ and then with respect to $y$, whereas in computing $f_{yx}$ the order is reversed.

}

\defrose{Clairut's Theorem}{
	DDefintion: Suppose $f$ is defined on a disk $D$ that contains the point $(a,b)$. If the functions $f_{xy}$ and $f_{yx}$ are both continuous on $D$, then
    \[
    f_{xy}(a, b) = f_{yx}(a, b)
    \]
}

\section{14.4 Tangent Planes and Linear Approximation}

\defrose{Tangent Planes}{
	LLet's consider a surface \( S \) given by the equation \( z = f(x, y) \),
	where \( f \) has continuous first derivatives. Let \( P(x_0, y_0, z_0) \) be a
	point on the surface. Two curves, \( C_1 \) and \( C_2 \), are formed by slicing
	the surface with vertical planes \( y = y_0 \) and \( x = x_0 \). These curves pass
	through the point \( P \). The tangent lines to \( C_1 \) and \( C_2 \) at \( P \) 
	are denoted \( T_1 \) and \( T_2 \). The \textbf{tangent plane} to the surface at \( P \) 
	is the plane that contains both tangent lines \( T_1 \) and \( T_2 \).

	\insertpng[0.25]{plane.png}
}

\defrose{Equation of a tangent plan}{
	SSuppose $f$ has continuous partial derivatives. An equation of the tangent plane to the surface $z = f(x, y)$ at the point $P(x_0, y_0, z_0)$ is
	\begin{equation}
		z - z_0 = f_x(x_0, y_0)(x - x_0) + f_y(x_0, y_0)(y - y_0) 
	\end{equation}
}

\defrose{Linear Approximations}{
	IIf $z = f(x, y)$, then $f$ is \textbf{differentiable} at $(a, b)$ if $\Delta z$ can be expressed in the form
	\begin{equation}
		\Delta z = f_x(a, b) \Delta x + f_y(a, b) \Delta y + \epsilon_1 \Delta x + \epsilon_2 \Delta y
	\end{equation}
	where $\epsilon_1$ and $\epsilon_2$ are functions of $\Delta x$ and $\Delta y$ such that $\epsilon_1$ and $\epsilon_2 \to 0$ as $(\Delta x, \Delta y) \to (0, 0)$.
}

\section{14.5 The Chain Rule}

\defrose{Chain Rule (Case 1)}{
	SSuppose that $z = f(x, y)$ is a differentiable function of $x$ and $y$, where $x = g(t)$ and $y = h(t)$ are both differentiable functions of $t$. Then $z$ is a differentiable function of $t$ and
	\begin{equation}
		\frac{dz}{dt} = \frac{\partial f}{\partial x} \frac{dx}{dt} + \frac{\partial f}{\partial y} \frac{dy}{dt}
	\end{equation}
	\begin{equation}
		\frac{dz}{dt} = \frac{\partial z}{\partial z} \frac{dx}{dt} + \frac{\partial z}{\partial y} \frac{dy}{dt} 
	\end{equation}
}

\defrose{Chain Rule (Case 2)}{
	SSuppose that $z = f(x, y)$ is a differentiable function of $x$ and $y$, where $x = g(s, t)$ and $y = h(s, t)$ are differentiable functions of $s$ and $t$. Then
	\begin{equation}
		\frac{\partial z}{\partial s} = \frac{\partial z}{\partial x} \frac{\partial x}{\partial s} + \frac{\partial z}{\partial y} \frac{\partial y}{\partial s}
	\end{equation}
	
	\begin{equation}
		\frac{\partial z}{\partial t} = \frac{\partial z}{\partial x} \frac{\partial x}{\partial t} + \frac{\partial z}{\partial y} \frac{\partial y}{\partial t}
	\end{equation}
	
}

\defrose{Chain Rule (General Case)}{
	SSuppose that $u$ is a differentiable function of the $n$ variables $x_1, x_2, \dots, x_n$ and each $x_j$ is a differentiable function of the $m$ variables $t_1, t_2, \dots, t_m$. Then $u$ is a function of $t_1, t_2, \dots, t_m$ and
	\begin{equation}
		\frac{\partial u}{\partial t_i} = \frac{\partial u}{\partial x_1} \frac{\partial x_1}{\partial t_i} + \frac{\partial u}{\partial x_2} \frac{\partial x_2}{\partial t_i} + \dots + \frac{\partial u}{\partial x_n} \frac{\partial x_n}{\partial t_i}
	\end{equation}
	for each $i = 1, 2, \dots, m$.
}

\defrose{Implicit Differentiation}{
	DDefintion: 
	\begin{equation}
		\frac{dy}{dx} = - \frac{\frac{\partial F}{\partial x}}{\frac{\partial F}{\partial Y}} = - \frac{F_{x}}{F_{y}}
	\end{equation}

	\begin{equation}
		\frac{\partial z}{\partial x} = - \frac{\frac{\partial F}{\partial x}}{\frac{\partial F}{\partial z}} = -\frac{F_x}{F_z}
	\end{equation}

	\begin{equation}
		\frac{\partial z}{\partial y} = - \frac{\frac{\partial F}{\partial y}}{\frac{\partial F}{\partial z}} = -\frac{F_y}{F_z}
	\end{equation}
}

\section{14.6 Directional Derivatives and the Gradient Vector}

\defrose{Directional Derivative}{
	DDefintion: The \textbf{directional derivative} of $f$ at $(x_0, y_0)$ in the direction of a unit vector $\mathbf{u} = \langle a, b \rangle$ is
	\begin{equation}
		D_{\mathbf{u}} f(x_0, y_0) = \lim_{h \to 0} \frac{f(x_0 + ha, y_0 + hb) - f(x_0, y_0)}{h}
	\end{equation}
	if this limit exists.
}

\thm{}{
	If $f$ is a differentiable function of $x$ and $y$, then $f$ has a directional derivative in the direction of any unit vector $\mathbf{u} = \langle a, b \rangle$ and
	\begin{equation}
		D_{\mathbf{u}} f(x, y) = f_x(x, y) a + f_y(x, y) b
	\end{equation}
}

\defrose{The Gradient Vector}{
	IIf $f$ is a function of two variables $x$ and $y$, then the \textbf{gradient} of $f$ is the vector function $\nabla f$ defined by
	\begin{equation}
		\nabla f(x, y) = \langle f_x(x, y), f_y(x, y) \rangle = \frac{\partial f}{\partial x} \mathbf{i} + \frac{\partial f}{\partial y} \mathbf{j}	
	\end{equation}
}

\ntimg{
	Equation 3.12 can be rewritten as 
	\begin{equation}
		D_{u}f(x,y) = \nabla f(x,y) \cdot \textbf{u} 
	\end{equation}
}

\defrose{Gradient of Three Variable Functions}{
	DDefintion: 
	\begin{equation}
		\nabla f = \langle f_x, f_y, f_z \rangle = \frac{\partial f}{\partial x} \mathbf{i} + \frac{\partial f}{\partial y} \mathbf{j} + \frac{\partial f}{\partial z} \mathbf{k}
	\end{equation}
}

\thm{Maximizing Directional Derivative}{
	Suppose $f$ is a differentiable function of two or three variables. The maximum value of the 
	directional derivative $D_{\mathbf{u}} f(\mathbf{x})$ is $\lvert \nabla f(\mathbf{x}) 
	\rvert$ and it occurs when $\mathbf{u}$ has the same direction as the gradient vector 
	$\nabla f(\mathbf{x})$.
}

\defrose{Tanget Planes to Level Surfaces}{
	CConsider a surface \( S \) defined by \( F(x, y, z) = k \), where \( F \) is a function of three variables. 
	Let \( P(x_0, y_0, z_0) \) be a point on \( S \) and \( C \) be a curve on \( S \) that passes \
	through \( P \). The curve is given by a vector function \( \mathbf{r}(t) = \langle x(t), y(t), z(t) \rangle \) 
	such that \( \mathbf{r}(t_0) = \langle x_0, y_0, z_0 \rangle \). Since \( C \) lies on \( S \), 
	the equation \( F(x(t), y(t), z(t)) = k \) must hold. \\

	By using the Chain Rule to differentiate both sides of this equation, we get:
	\[
	\frac{\partial F}{\partial x} \frac{dx}{dt} + \frac{\partial F}{\partial y} \frac{dy}{dt} + \frac{\partial F}{\partial z} \frac{dz}{dt} = 0
	\]
	
	This can be written as a dot product:
	\[
	\nabla F \cdot \mathbf{r}'(t) = 0
	\]
	which means that the gradient \( \nabla F \) is perpendicular to the tangent vector \( \mathbf{r}'(t) \) at \( P \).
	
	At \( t = t_0 \), the gradient at \( P \), \( \nabla F(x_0, y_0, z_0) \), is normal to the tangent plane at \( P \). The equation of the tangent plane is:
	\begin{equation}
		F_x(x_0, y_0, z_0)(x - x_0) + F_y(x_0, y_0, z_0)(y - y_0) + F_z(x_0, y_0, z_0)(z - z_0) = 0
	\end{equation}
}

\ntimg{
	\textbf{Properties of the Gradient Vecotr} \\
	Let $f$ be a differentiable function of two or three variables and suppose that $\nabla f(\mathbf{x}) \neq 0$.
	\begin{itemize}
		\item The directional derivative of $f$ at $\mathbf{x}$ in the direction of a unit vector $\mathbf{u}$ is given by $D_{\mathbf{u}} f(\mathbf{x}) = \nabla f(\mathbf{x}) \cdot \mathbf{u}$.
		\item $\nabla f(\mathbf{x})$ points in the direction of maximum rate of increase of $f$ at $\mathbf{x}$, and that maximum rate of change is $\lvert \nabla f(\mathbf{x}) \rvert$.
		\item $\nabla f(\mathbf{x})$ is perpendicular to the level curve or level surface of $f$ through $\mathbf{x}$.
	\end{itemize}
}

\section{14.7 Maxium and Minimum Values}

\defrose{Local Min and Max}{
	DDefintion: A function of two variables has a \textbf{local maximum} at $(a, b)$ if $f(x, y) \leq f(a, b)$ when $(x, y)$ is near $(a, b)$. [This means that $f(x, y) \leq f(a, b)$ for all points $(x, y)$ in some disk with center $(a, b)$.] The number $f(a, b)$ is called a \textbf{local maximum value}. If $f(x, y) \geq f(a, b)$ when $(x, y)$ is near $(a, b)$, then $f$ has a \textbf{local minimum} at $(a, b)$ and $f(a, b)$ is a \textbf{local minimum value}.
}

\thm{Critical Point}{
	If $f$ has a local maximum or minimum at $(a, b)$ and the first-order partial derivatives of $f$ exist there, then $f_x(a, b) = 0$ and $f_y(a, b) = 0$.
}

\defrose{Second Derivatives Test}{
	SSuppose the second partial derivatives of $f$ are continuous on a disk with center $(a, b)$, and suppose that $f_x(a, b) = 0$ and $f_y(a, b) = 0$ [so $(a, b)$ is a critical point of $f$]. Let
	\begin{equation}
	D = D(a, b) = f_{xx}(a, b) f_{yy}(a, b) - [f_{xy}(a, b)]^2
	\end{equation}
	\begin{itemize}
		\item[(a)] If $D > 0$ and $f_{xx}(a, b) > 0$, then $f(a, b)$ is a local minimum.
		\item[(b)] If $D > 0$ and $f_{xx}(a, b) < 0$, then $f(a, b)$ is a local maximum.
		\item[(c)] If $D < 0$, then $(a, b)$ is a saddle point of $f$.
	\end{itemize}
}

\defrose{Absolute Maxiums and Absolute Minimums}{
	LLet $(a, b)$ be a point in the domain $D$ of a function $f$ of two variables. Then $f(a, b)$ is the
	\begin{itemize}
		\item \textbf{absolute maximum} value of $f$ on $D$ if $f(a, b) \geq f(x, y)$ for all $(x, y)$ in $D$.
		\item \textbf{absolute minimum} value of $f$ on $D$ if $f(a, b) \leq f(x, y)$ for all $(x, y)$ in $D$.
	\end{itemize}
}

\defrose{Extreme Value Theorem for Functions of Two Variables}{
	IIf $f$ is continuous on a closed, bounded set $D$ in $\mathbb{R}^2$, then $f$ 
	attains an absolute maximum value $f(x_1, y_1)$ and an absolute minimum value 
	$f(x_2, y_2)$ at some points $(x_1, y_1)$ and $(x_2, y_2)$ in $D$.
}

\ntimg{To find the absolute maximum and minimum values of a continuous function $f$ on a closed, bounded set $D$:
	\begin{enumerate}
		\item Find the values of $f$ at the critical points of $f$ in $D$.
		\item Find the extreme values of $f$ on the boundary of $D$.
		\item The largest of the values from steps 1 and 2 is the absolute maximum value; the smallest of these values is the absolute minimum value.
	\end{enumerate}
}

\section{14.8 Lagrange Multipliers}

\defrose{Geometric Explanation Lagrange Multipliers (One Constraint)}{
	TThe geometric basis of Lagrange's method for two variables involves finding the extreme
	values of \( f(x, y) \) under the constraint \( g(x, y) = k \). This means finding the
	extreme values of \( f \) along the level curve defined by \( g(x, y) = k \). 
	To maximize \( f(x, y) \) subject to this constraint, we look for the largest value 
	of \( f \) where its level curve touches the constraint curve at one point. At this 
	point, the gradients of \( f \) and \( g \) are parallel, which gives the 
	relationship \( \nabla f(x_0, y_0) = \lambda \nabla g(x_0, y_0) \) for some 
	scalar \( \lambda \). \\

	This reasoning also applies to functions of three variables. To find extreme values 
	of \( f(x, y, z) \) under the constraint \( g(x, y, z) = k \), the point \( (x, y, z) \)
	must lie on the level surface defined by \( g(x, y, z) = k \). The gradients of 
	\( f \) and \( g \) are again parallel at the point where the maximum value of \( f \) 
	is reached. \\

	To make this precise, consider a curve \( C \) on the surface 
	where \( g(x, y, z) = k \). The function \( f \) has an extreme value at the
	point \( P(x_0, y_0, z_0) \). If we parameterize the curve as
	\( \mathbf{r}(t) = \langle x(t), y(t), z(t) \rangle \), then \( f \) has an 
	extreme value at \( t_0 \) when \( h'(t_0) = 0 \), where \( h(t) = f(\mathbf{r}(t)) \). 
	Using the Chain Rule, we find that the gradients are again parallel.
}

\defrose{Method of Lagrange Multipliers}{
	TTo find the maximum and minimum values of $f(x, y, z)$ subject to the constraint $g(x, y, z) = k$ [assuming that these extreme values exist and $\nabla g \neq 0$ on the surface $g(x, y, z) = k$]:

	\begin{enumerate}
		\item Find all values of $x$, $y$, $z$, and $\lambda$ such that
		\[
		\nabla f(x, y, z) = \lambda \nabla g(x, y, z)
		\]
		and
		\[
		g(x, y, z) = k
		\]
		\item Evaluate $f$ at all the points $(x, y, z)$ that result from step 1. The largest of these values is the maximum value of $f$; the smallest is the minimum value of $f$.
	\end{enumerate}
}

\defrose{Lagrange Multipliers Two Constraints}{
	TTo find the maximum and minimum values of \( f(x, y, z) \) subject to two constraints,
	\( g(x, y, z) = k \) and \( h(x, y, z) = c \), we look for extreme values when \
	\( (x, y, z) \) lies on the curve formed by the intersection of the level surfaces
	of \( g \) and \( h \). \\

	At the point where \( f \) has an extreme value, the gradient of 
	\( f \), \( \nabla f \), is orthogonal to the curve. The gradients of
	\( g \) and \( h \) are also orthogonal to this curve, which means \( \nabla f \)
	must lie in the plane formed by \( \nabla g \) and \( \nabla h \). \\
	
	Thus, there exist two numbers, \( \lambda \) and \( \mu \), called Lagrange multipliers,
	such that \( \nabla f(x_0, y_0, z_0) \) is a linear combination of 
	\( \nabla g(x_0, y_0, z_0) \) and \( \nabla h(x_0, y_0, z_0) \).	

	\begin{equation}
		\nabla f(x_0, y_0, z_0) = \lambda \nabla g(x_0, y_0, z_0) + \mu \nabla h(x_0, y_0, z_0)
	\end{equation}
}

\chapter{Multiple Integerals}

\section{15.1 Double Integral Over Rectangles}

\defrose{Volume of a Function}{
	WWe start with a function \( f \) defined over a closed rectangle \( R \) in the \( xy \)-plane, denoted as:

	\[ R = [a,b] \times [c,d] = \{(x,y) \in \mathbb{R}^2 \mid a \leq x \leq b, \, c \leq y \leq d\}. \]

	The goal is to find the volume of the solid \( S \), which lies above the rectangle \( R \) and below the graph of the surface \( z = f(x,y) \), defined as:

	\[ S = \{(x,y,z) \in \mathbb{R}^3 \mid 0 \leq z \leq f(x,y), \, (x,y) \in R\}. \]

	\insertpng[0.3]{vol.png}
}

\defrose{Volume of a Function (PART II)}{
	TTo compute this volume, we first divide the rectangle \( R \) into smaller subrectangles. The interval \( [a,b] \) is divided into \( m \) subintervals of equal width \( \Delta x = \frac{b-a}{m} \), and the interval \( [c,d] \) is divided into \( n \) subintervals of equal width \( \Delta y = \frac{d-c}{n} \). The subrectangles are denoted by:

	\[
	R_{ij} = [x_{i-1},x_i] \times [y_{j-1},y_j] = \{(x,y) \mid x_{i-1} \leq x \leq x_i, \, y_{j-1} \leq y \leq y_j\}.
	\]

	Each subrectangle has an area of \( \Delta A = \Delta x \Delta y \).

	\insertpng[0.3]{rect.png}

	Next, we approximate the volume of the solid \( S \) by choosing a sample point \( (x^*_{ij}, y^*_{ij}) \) in each subrectangle \( R_{ij} \). Using this point, we approximate the part of \( S \) above each \( R_{ij} \) by a thin rectangular box (or column) with base \( R_{ij} \) and height \( f(x^*_{ij}, y^*_{ij}) \). The volume of this box is:

	\[
	f(x^*_{ij}, y^*_{ij}) \Delta A.
	\]
	\insertpng[0.3]{approx.png}
}

\defrose{Volume of a Function (PART III)}{
	WWe then sum the volumes of all these boxes over the entire grid of subrectangles, obtaining an approximation of the total volume \( V \) of the solid \( S \):

	\[
	V \approx \sum_{i=1}^{m} \sum_{j=1}^{n} f(x^*_{ij}, y^*_{ij}) \Delta A.
	\]

	As \( m \) and \( n \) become larger, our approximation becomes more accurate. The exact volume of \( S \) is given by the limit of the double sum as \( m, n \to \infty \):

	\begin{equation}
		\iint_R f(x, y) \, dA = \lim_{m,n \to \infty} \sum_{i=1}^{m} \sum_{j=1}^{n} f(x^*_{ij}, y^*_{ij}) \, \Delta A
	\end{equation}

	\insertpng[0.3]{approxVol.png}
	This is the formal definition of the volume of the solid \( S \) that lies under the graph of the function \( f \) and above the rectangle \( R \). By taking the limit, we ensure that the approximation becomes exact.
}


\defrose{Double Integeral}{
	DDefintion: The \textbf{double integral} of \(f \) over the rectangle \(R \) is 
	\begin{equation}
		\iint\limits_R f(x, y) \, dA = \lim_{m,n \to \infty} \sum_{i=1}^{m} \sum_{j=1}^{n} f(x^*_{ij}, y^*_{ij}) \, \Delta A
	\end{equation}
	if this limit exists
}

\defrose{Equation for Volume}{
	IIf $f(x, y) \geq 0$, then the volume $V$ of the solid that lies above the rectangle $R$ and below the surface $z = f(x, y)$ is
        \begin{equation}
			V = \iint\limits_{R} f(x, y) \, dA
		\end{equation}
}

\defrose{Midpoint Rule for Double Integerals}{
	EEquation: 
	\begin{equation} 
		\iint\limits_{R} f(x, y) \, dA \approx \sum_{i=1}^{m} \sum_{j=1}^{n} f(\bar{x}_i, \bar{y}_j) \, \Delta A
    \end{equation}
    where $\bar{x}_i$ is the midpoint of $[x_{i-1}, x_i]$ and $\bar{y}_j$ is the midpoint of $[y_{j-1}, y_j]$.
}

\defrose{Fubini's Theorem}{
	IIf \( f \) is continuous on the rectangle
	\[ R = \{(x, y) \mid a \leq x \leq b, \ c \leq y \leq d\} \]
	then
	\[ \iint\limits_{R} f(x, y) \, dA = \int_a^b \int_c^d f(x, y) \, dy dx = \int_c^d \int_a^b f(x, y) \, dx dy \]
	More generally, this is true if we assume that \( f \) is bounded on \( R \), \( f \) is discontinuous only on a finite number of smooth curves, and the iterated integrals exist.
}

\defrose{Average Value}{
	WWe define the \textbf{average value} of a function \( f \) of two variables defined on a rectangle \( R \) to be
	\[
	f_{\text{avg}} = \frac{1}{A(R)} \iint\limits_{R} f(x, y) \, dA
	\]
	where \( A(R) \) is the area of \( R \).

	If \( f(x, y) \geq 0 \), the equation
	\[
	A(R) \times f_{\text{avg}} = \iint\limits_{R} f(x, y) \, dA
	\]
	holds true.
}

\section{15.2 Double Integrals over General Regions}

\defrose{General Regions}{
	CConsider a general region \( D \) which is bounded, which means that \( D \) can be enclosed in a rectangular region \( R \). In order to integrate a function \( f \) over \( D \), we define a new function \( F \) with domain \( R \) by
	\[
	F(x, y) =
	\begin{cases} 
	f(x, y) & \text{if } (x, y) \text{ is in } D \\
	0 & \text{if } (x, y) \text{ is in } R \text{ but not in } D
	\end{cases}
	\]
	\insertpng[0.35]{region.png}
	\[
	\iint\limits_{D} f(x, y) \, dA = \iint\limits_{R} F(x, y) \, dA
	\]
	where \( F \) is given by the above equation.
}

\defrose{Type 1}{
	AA plane region \( D \) is said to be of \textbf{type I} if it lies between the graphs of two continuous functions of \( x \), that is,
	\begin{equation}
		D = \{ (x, y) \mid a \leq x \leq b, \ g_1(x) \leq y \leq g_2(x) \}
	\end{equation}
	where \( g_1 \) and \( g_2 \) are continuous on \( [a, b] \).

	If \( f \) is continuous on a type I region \( D \) described by
	\[
	D = \{(x, y) \mid a \leq x \leq b, \ g_1(x) \leq y \leq g_2(x)\}
	\]
	then
	\begin{equation}
		\iint\limits_{D} f(x, y) \, dA = \int_a^b \int_{g_1(x)}^{g_2(x)} f(x, y) \, dy dx
	\end{equation}

}


\defrose{Type II}{
	I If \( f \) is continuous on a type II region \( D \) described by
	\begin{equation}
		D = \{(x, y) \mid c \leq y \leq d, \ h_1(y) \leq x \leq h_2(y)\}
	\end{equation}
	then
	\begin{equation}
		\iint\limits_{D} f(x, y) \, dA = \int_c^d \int_{h_1(y)}^{h_2(y)} f(x, y) \, dx dy	
	\end{equation}
}

\newpage 

\ntimg{
	\textbf{Properties of Integerals}
	\begin{itemize}
		\item 
		\begin{equation}
			\iint\limits_{D} [f(x, y) + g(x, y)] \, dA = \iint\limits_{D} f(x, y) \, dA + \iint\limits_{D} g(x, y) \, dA
		\end{equation}
		
		\item 
		\begin{equation}
			\iint\limits_{D} c f(x, y) \, dA = c \iint\limits_{D} f(x, y) \, dA \quad \text{where \( c \) is a constant.}
		\end{equation}
		
		\item  If \( f(x, y) \geq g(x, y) \) for all \( (x, y) \in D \), then
		\begin{equation}
			\iint\limits_{D} f(x, y) \, dA \geq \iint\limits_{D} g(x, y) \, dA
		\end{equation}
		
		\item If \( D = D_1 \cup D_2 \) where \( D_1 \) and \( D_2 \) don't overlap except perhaps on their boundaries, then
		\begin{equation}
			\iint\limits_{D} f(x, y) \, dA = \iint\limits_{D_1} f(x, y) \, dA + \iint\limits_{D_2} f(x, y) \, dA
		\end{equation}	

		\item If we integrate the constant function $f(x,y) = 1$ over a region \( D \), we get the area of \( D \)  
		\begin{equation}
			\iint\limits_D 1 \, dA = A(D)
		\end{equation}
		
		\item If \( m \leq f(x, y) \leq M \) for all \( (x, y) \in D \), then
		\begin{equation}
			m \cdot A(D) \leq \iint\limits_D f(x, y) \, dA \leq M \cdot A(D)
		\end{equation}
	\end{itemize}
}


\section{Double Integrals in Polar Coodinates}





\end{document}
